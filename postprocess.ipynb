{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import logging\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rc\n",
    "import pickle\n",
    "from datetime import date\n",
    "\n",
    "# from util import *\n",
    "# from hilbert import hilbert_xxz\n",
    "# from spectral_net import *\n",
    "from config import deepqd_config\n",
    "from DQD_leftover import *\n",
    "# from VanillaQD import VanillaQD\n",
    "from ClsQuantumDynamics import QuantumDynamics as clsQD\n",
    "\n",
    "\n",
    "T = 32*10\n",
    "directory =  '/home/bingjiay/gpfs/ControlQD'\n",
    "# config_dict = directory + '/config/20-10-16-19-30-28s16n16-20b16-20MC4000hd128-cell4-lr0.001_skip*4NN0'\n",
    "# config_dict = directory + '/config/20-10-16-15-15-45s16n32-20b32-20MC4000hd128-cell4-lr0.001_skip*4NN0'\n",
    "# config_dict = directory + '/config/20-10-16-15-16-00s16n64-20b64-20MC4000hd128-cell4-lr0.001_skip*4NN0'\n",
    "\n",
    "# config_dict = directory + '/config/20-10-12-02-47-58s24n48-20b48-20MC4000hd128-cell4-lr0.001_skip*4NN0'\n",
    "# config_dict = directory + '/config/20-10-12-02-26-46s24n24-20b24-20MC4000hd128-cell4-lr0.001_skip*4NN0'\n",
    "\n",
    "# config_dict = directory + '/config/20-10-12-02-48-24s32n32-20b32-20MC4000hd128-cell4-lr0.001_skip*4NN0'\n",
    "# config_dict = directory + '/config/20-10-13-02-43-27s32n48-20b48-20MC4000hd128-cell4-lr0.001_skip*4NN0'\n",
    "## wall\n",
    "# config_dict = directory + '/config/20-10-19-00-35-59s16n32-20b32-20MC4000hd128-cell4-lr0.001_wallNN0'\n",
    "\n",
    "# config_dict = directory + '/config/20-10-19-01-48-31s24n24-20b24-20MC4000hd128-cell4-lr0.001_wallNN0'\n",
    "# config_dict = directory + '/config/20-10-19-10-18-10s24n24-20b48-20MC8000hd128-cell4-lr0.001_wallNN0'\n",
    "\n",
    "config_dict = directory + '/config/20-10-19-01-49-39s32n32-20b32-20MC4000hd128-cell4-lr0.001_wallNN0'\n",
    "# config_dict = directory + '/config/20-10-19-11-29-04s32n32-20b64-20MC4000hd128-cell4-lr0.001_wallNN0'\n",
    "# config_dict = directory + '/config/20-10-21-20-19-14s32n32-20b32-20MC8000hd128-cell4-lr0.001_wall-lowlyingNN0'\n",
    "# config_dict = directory + '/config/20-10-22-04-10-26s32n32-20b96-20MC4000hd128-cell4-lr0.001_wallNN0'\n",
    "\n",
    "\n",
    "\n",
    "# config_dict = directory + '/config/20-10-19-21-29-00s40n20-20b40-20MC8000hd128-cell4-lr0.001_wallNN0'\n",
    "# config_dict = directory + '/config/20-10-20-10-36-32s40n20-20b40-20MC4000hd128-cell4-lr0.001_wall-losscutNN0'\n",
    "# config_dict = directory + '/config/20-10-20-12-58-55s40n20-20b80-20MC4000hd128-cell4-lr0.001_wall-losscutNN0'\n",
    "# config_dict = directory + '/config/20-10-20-14-56-52s40n20-20b20-20MC4000hd128-cell4-lr0.001_wall-losscutNN0'\n",
    "# config_dict = directory + '/config/20-10-20-16-35-18s40n10-20b40-20MC8000hd128-cell4-lr0.001_wall-losscutNN0'\n",
    "\n",
    "# config_dict = directory + '/config/20-10-21-12-54-54s40n20-20b20-20MC10000hd128-cell4-lr0.001_wall-lowlyingNN0'\n",
    "\n",
    "\n",
    "### Initialization\n",
    "args = deepqd_config()\n",
    "with open(config_dict,'rb') as f:\n",
    "    args.__dict__ = pickle.load(f)\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    args.device = 'cuda'\n",
    "    args.num_device = 2\n",
    "else:\n",
    "    args.device = 'cpu'\n",
    "#####\n",
    "# data_dir = './nn_data/' + args.experiment_name\n",
    "output_dir = './output/' + args.experiment_name\n",
    "# if not os.path.exists(data_dir):\n",
    "#     os.mkdir(data_dir)\n",
    "#     print(\"Directory \" , data_dir ,  \" Created \")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    print(\"Directory \" , output_dir ,  \" Created \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /home/bingjiay/gpfs/ControlQD/nn_data/s32n32-20b32-20MC4000hd128-cell4-lr0.001_wall/0.net\n",
      "working on t=0.0, exact=False\n",
      "working on t=3.2, exact=False\n",
      "working on t=6.4, exact=False\n",
      "working on t=9.6, exact=False\n",
      "working on t=12.8, exact=False\n",
      "working on t=16.0, exact=False\n",
      "working on t=19.2, exact=False\n",
      "working on t=22.400000000000002, exact=False\n",
      "working on t=25.6, exact=False\n",
      "working on t=28.799999999999997, exact=False\n",
      "working on t=32.0, exact=False\n",
      "working on t=35.2, exact=False\n",
      "working on t=38.4, exact=False\n",
      "working on t=41.6, exact=False\n",
      "working on t=44.800000000000004, exact=False\n",
      "working on t=48.0, exact=False\n",
      "working on t=51.2, exact=False\n",
      "working on t=54.400000000000006, exact=False\n",
      "working on t=57.599999999999994, exact=False\n",
      "working on t=60.8, exact=False\n",
      "working on t=64.0, exact=False\n",
      "working on t=67.2, exact=False\n",
      "working on t=70.4, exact=False\n",
      "working on t=73.60000000000001, exact=False\n",
      "working on t=76.8, exact=False\n",
      "working on t=80.0, exact=False\n",
      "working on t=83.2, exact=False\n",
      "working on t=86.4, exact=False\n",
      "working on t=89.60000000000001, exact=False\n",
      "working on t=92.8, exact=False\n",
      "working on t=96.0, exact=False\n",
      "working on t=99.2, exact=False\n",
      "working on t=102.4, exact=False\n",
      "working on t=105.60000000000001, exact=False\n",
      "working on t=108.80000000000001, exact=False\n",
      "working on t=112.0, exact=False\n",
      "working on t=115.19999999999999, exact=False\n",
      "working on t=118.4, exact=False\n",
      "working on t=121.6, exact=False\n",
      "working on t=124.80000000000001, exact=False\n",
      "working on t=128.0, exact=False\n",
      "working on t=131.2, exact=False\n",
      "working on t=134.4, exact=False\n",
      "working on t=137.6, exact=False\n",
      "working on t=140.8, exact=False\n",
      "working on t=144.0, exact=False\n",
      "working on t=147.20000000000002, exact=False\n",
      "working on t=150.39999999999998, exact=False\n",
      "working on t=153.6, exact=False\n",
      "working on t=156.8, exact=False\n",
      "working on t=160.0, exact=False\n",
      "working on t=163.2, exact=False\n",
      "working on t=166.4, exact=False\n",
      "working on t=169.60000000000002, exact=False\n",
      "working on t=172.8, exact=False\n",
      "working on t=176.0, exact=False\n",
      "working on t=179.20000000000002, exact=False\n",
      "working on t=182.39999999999998, exact=False\n",
      "working on t=185.6, exact=False\n",
      "working on t=188.79999999999998, exact=False\n",
      "working on t=192.0, exact=False\n",
      "working on t=195.2, exact=False\n",
      "working on t=198.4, exact=False\n",
      "working on t=201.6, exact=False\n",
      "working on t=204.8, exact=False\n",
      "working on t=208.0, exact=False\n",
      "working on t=211.20000000000002, exact=False\n",
      "working on t=214.4, exact=False\n",
      "working on t=217.60000000000002, exact=False\n",
      "working on t=220.79999999999998, exact=False\n",
      "working on t=224.0, exact=False\n",
      "working on t=227.2, exact=False\n",
      "working on t=230.39999999999998, exact=False\n",
      "working on t=233.6, exact=False\n",
      "working on t=236.8, exact=False\n",
      "working on t=240.0, exact=False\n",
      "working on t=243.2, exact=False\n",
      "working on t=246.4, exact=False\n",
      "working on t=249.60000000000002, exact=False\n",
      "working on t=252.8, exact=False\n",
      "working on t=256.0, exact=False\n",
      "working on t=259.20000000000005, exact=False\n",
      "working on t=262.4, exact=False\n",
      "working on t=265.59999999999997, exact=False\n",
      "working on t=268.8, exact=False\n",
      "working on t=272.0, exact=False\n",
      "working on t=275.2, exact=False\n",
      "working on t=278.4, exact=False\n",
      "working on t=281.6, exact=False\n",
      "working on t=284.8, exact=False\n",
      "working on t=288.0, exact=False\n",
      "working on t=291.2, exact=False\n",
      "working on t=294.40000000000003, exact=False\n",
      "working on t=297.6, exact=False\n",
      "working on t=300.79999999999995, exact=False\n",
      "working on t=304.0, exact=False\n",
      "working on t=307.2, exact=False\n",
      "working on t=310.4, exact=False\n",
      "working on t=313.6, exact=False\n",
      "working on t=316.8, exact=False\n",
      "working on t=320.0, exact=False\n"
     ]
    }
   ],
   "source": [
    "nbatch = 12000\n",
    "reps = 20\n",
    "stype='wall'\n",
    "for depth in [0]:\n",
    "    deepqd = spectral_tree(args)\n",
    "    ham = deepqd.hilbert\n",
    "    exact_sampling = True if ham.Lx<20 else False\n",
    "    out_appdix = 'exact.png' if exact_sampling else 'mc.png'\n",
    "\n",
    "    try:\n",
    "        with open('./benchmark/{}Jz-1L32T10.0.tenpy'.format(stype),'rb') as file:\n",
    "            ref_Jt = pickle.load(file)\n",
    "            ref_entropy = pickle.load(file)\n",
    "            ref_szsz_avg = pickle.load(file)\n",
    "            ref_stagger_avg = pickle.load(file)\n",
    "            ref_sdw_avg = pickle.load(file)\n",
    "    except:\n",
    "        print('can not load benchmarking data')\n",
    "\n",
    "    if depth>0:\n",
    "        deepqd.load_tree(directory)\n",
    "        deepqd.load_all_model(directory=directory)\n",
    "    else:\n",
    "        deepqd.load_model('0',directory=directory)\n",
    "    time = np.arange(101) / 100 * T\n",
    "    entropy_list = []\n",
    "    nn_coupling_list = []\n",
    "    spin_imbalance_list = []\n",
    "    mirror_szsz_list = []\n",
    "    spin_density = []\n",
    "    for t in time:\n",
    "        print('working on t={}, exact={}'.format(t,exact_sampling))\n",
    "        if exact_sampling:\n",
    "            entropy, szsz_avg, stagger_avg, sdw_avg = deepqd.get_observation(depth,t,exact=True)\n",
    "        else:\n",
    "            entropy ,szsz_avg, mirror_szsz_avg, stagger_avg, sdw_avg = 0, 0, 0,0, 0\n",
    "            for q in range(reps):\n",
    "                _, szsz, mirror_szsz, stagger, sdw = deepqd.get_observation(depth=depth,t=t,batchsize=nbatch)\n",
    "                szsz_avg += szsz / reps\n",
    "                mirror_szsz_avg += mirror_szsz / reps\n",
    "                stagger_avg += stagger / reps\n",
    "                sdw_avg += sdw / reps\n",
    "        entropy_list.append(entropy)\n",
    "        nn_coupling_list.append(szsz_avg)\n",
    "        mirror_szsz_list.append(mirror_szsz_avg)\n",
    "        spin_imbalance_list.append(stagger_avg)\n",
    "        spin_density.append(sdw_avg)\n",
    "\n",
    "    entropy = np.array(entropy_list)\n",
    "    nn_coupling = np.array(nn_coupling_list)\n",
    "    mirror_szsz = np.array(mirror_szsz_list)\n",
    "    spin_imbalance = np.array(spin_imbalance_list)\n",
    "    spin_density = np.array(spin_density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.linewidth'] = 2.0 #set the value globally\n",
    "\n",
    "font = {'family': 'serif',\n",
    "        'color':  'k',\n",
    "        'weight': 'normal',\n",
    "        'size': 10,\n",
    "        }\n",
    "\n",
    "L = ham.Lx\n",
    "###### plot  spin wave\n",
    "for i in range(0,deepqd.nspin,1) :\n",
    "    plt.scatter(np.array(time) * args.Jx, spin_density[:,i], marker = '.')#, label='spin '+str(i)+'deepqd')\n",
    "    try:\n",
    "        plt.plot(np.array(time_cls) * args.Jx, spin_density_cls[:,i],label=str(i))#, label='spin '+str(i)+'vanilla')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        plt.plot(ref_Jt, ref_sdw_avg.transpose()[i])\n",
    "    except:\n",
    "        pass\n",
    "plt.xlabel(r'$Jt$',fontdict=font)\n",
    "plt.ylabel(r'$\\langle\\sigma_i(t)\\rangle$',fontdict=font)\n",
    "plot_dir  = \"./output/{}/l{}T{}\".format( args.experiment_name, depth,T) + out_appdix\n",
    "plt.savefig(plot_dir,dpi=150)\n",
    "plt.close()\n",
    "\n",
    "### sdw at the boundary\n",
    "idx_list = [0, L//2-1, L//2, -1, L//4-1, L//4, L//4-1+L//2, L//4+L//2]\n",
    "color_list = ['b','c','k','g','m','r','y','purple']\n",
    "marker = ['x','.','x','.','x','.','x','.']\n",
    "for idx, i in  enumerate(idx_list):\n",
    "    x = args.Jx * np.array(time)\n",
    "    sparse_filter = (np.arange(x.shape[0]) % 5) == 0\n",
    "    ref_spin_density = np.roll(ref_sdw_avg,L//4,axis=1)\n",
    "    plt.plot(ref_Jt, ref_spin_density[:,i], \n",
    "             color=color_list[idx],linewidth=3)\n",
    "    plt.scatter( x[sparse_filter], spin_density[:,i][sparse_filter], \n",
    "                s = np.ones_like(sparse_filter)*169,\n",
    "                marker = marker[idx],\n",
    "                color=color_list[idx], label=r'$s_{'+str((i-8)%32+1)+'}$')\n",
    "    \n",
    "\n",
    "plt.xlabel(r'$Jt$',fontdict=font)\n",
    "plt.ylabel(r'$\\langle\\sigma_i(t)\\rangle$',fontdict=font)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(direction='in',labelsize=28)\n",
    "lgd = plt.legend(fontsize=16,bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "\n",
    "plot_dir  = \"./output/{}/boundary_sdw_l{}T{}\".format( args.experiment_name, depth,T) + out_appdix\n",
    "plt.savefig(plot_dir,dpi=150,bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "##### predicted sdw\n",
    "plt.subplot(311)\n",
    "ax = plt.gca()\n",
    "plt.imshow(np.roll(spin_density.transpose(),-8,axis=0), cmap='viridis', \n",
    "           interpolation='nearest',\n",
    "           aspect = 0.25,\n",
    "           #aspect =spin_density.shape[0]/spin_density.shape[1],\n",
    "          extent=[0,10,0,L+1])\n",
    "# plt.xlabel(r'$Jt$')\n",
    "#     plt.ylabel(r'$\\langle\\sigma_i(t)\\sigma_{i+d}(t)\\rangle$')\n",
    "plt.ylabel(r'$i$',fontdict=font)\n",
    "plt.xticks([], [])\n",
    "plt.yticks([0,10,20,30], [0,10,20,30])\n",
    "ax.tick_params(direction='in',labelsize=10)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(axis='y',direction='in',labelsize=8)\n",
    "\n",
    "##### reference sdw\n",
    "plt.subplot(312)\n",
    "ax = plt.gca()\n",
    "plt.imshow(ref_sdw_avg.transpose(), cmap='viridis', interpolation='nearest',\n",
    "           #aspect =ref_sdw_avg.shape[0]/ref_sdw_avg.shape[1],\n",
    "          aspect = 0.25,\n",
    "          extent=[0,10,0,L+1])\n",
    "# plt.xlabel(r'$Jt$')\n",
    "plt.ylabel(r'$i$',fontdict=font)\n",
    "plt.xticks([], [],fontname=\"Times\")\n",
    "plt.yticks([0,10,20,30], [0,10,20,30])\n",
    "ax.tick_params(direction='in',labelsize=10)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(axis='y',direction='in',labelsize=8)\n",
    "\n",
    "###### mirror correlation\n",
    "plt.subplot(313)\n",
    "ax = plt.gca()\n",
    "szsz = spin_density[:,:L//2] * np.flip(spin_density[:,L//2:],1)\n",
    "mirror_corr = mirror_szsz-szsz\n",
    "mirror_corr = (mirror_corr[:,:L//4] + np.flip(mirror_corr[:,L//4:],1))/2\n",
    "plt.imshow(mirror_corr.transpose(), cmap='gray', interpolation='nearest',\n",
    "           aspect =1.025,extent=[0,10,L//4+0.5,0.5])\n",
    "plt.xlabel(r'$Jt$',fontdict=font)\n",
    "plt.ylabel(r'$i$',fontdict=font)\n",
    "\n",
    "plt.xticks(np.arange(0,11,2), np.arange(0,11,2))\n",
    "plt.yticks(np.arange(1,9,2), np.arange(8,0,-2))\n",
    "\n",
    "ax.tick_params(direction='in',labelsize=10)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(axis='y',direction='in',labelsize=8)\n",
    "    \n",
    "plot_dir  = \"./output/{}/SDW_l{}T{}\".format( args.experiment_name, depth,T) + out_appdix\n",
    "plt.savefig(plot_dir,dpi=150)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# ###### averaged correlation\n",
    "# szsz = np.zeros_like(nn_coupling)\n",
    "# for d in range(ham.Lx//2):\n",
    "#     szsz[:,d] = (spin_density * np.roll(spin_density,d+1,axis=1)).mean(1)\n",
    "# plt.imshow((nn_coupling-szsz).transpose(), cmap='hot', interpolation='nearest',aspect ='auto')\n",
    "# plt.xlabel(r'$Jt$')\n",
    "# #     plt.ylabel(r'$\\langle\\sigma_i(t)\\sigma_{i+d}(t)\\rangle$')\n",
    "# plt.ylabel(r'$d$')\n",
    "# plt.colorbar()\n",
    "# plt.legend()\n",
    "# plot_dir  = \"./output/{}/correlation_l{}T{}\".format( args.experiment_name, depth,T) + out_appdix\n",
    "# plt.savefig(plot_dir,dpi=150)\n",
    "# plt.close()\n",
    "\n",
    "# ###### averaged szsz\n",
    "# plt.imshow(nn_coupling.transpose(), cmap='hot', interpolation='nearest',aspect ='auto')\n",
    "# plt.xlabel(r'$Jt$')\n",
    "# #     plt.ylabel(r'$\\langle\\sigma_i(t)\\sigma_{i+d}(t)\\rangle$')\n",
    "# plt.ylabel(r'$d$')\n",
    "# plt.colorbar()\n",
    "# plt.legend()\n",
    "# plot_dir  = \"./output/{}/szsz_l{}T{}\".format( args.experiment_name, depth,T) + out_appdix\n",
    "# plt.savefig(plot_dir,dpi=150)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2390625  -0.21718751 -0.1953125  -0.1734375  -0.1515625  -0.1296875\n",
      " -0.10781251 -0.0859375  -0.06406251 -0.04218751 -0.0203125   0.00156249\n",
      "  0.02343749  0.04531248  0.0671875   0.0890625   0.11093749  0.13281249\n",
      "  0.15468748  0.1765625   0.1984375   0.22031249  0.24218749  0.26406252\n",
      "  0.2859375   0.3078125   0.32968748  0.3515625   0.37343752  0.3953125\n",
      "  0.4171875   0.43906248]\n",
      "Emax=0.4390624761581421,Emin=-0.23906250298023224,dE=0.021875008940696716\n"
     ]
    }
   ],
   "source": [
    "### sdw at the boundary\n",
    "idx_list = [0, L//2-1, L//2, -1, L//4-1, L//4, L//4-1+L//2, L//4+L//2]\n",
    "color_list = ['b','c','k','g','m','r','y','purple']\n",
    "marker = ['x','.','x','.','x','.','x','.']\n",
    "for idx, i in  enumerate(idx_list):\n",
    "    x = args.Jx * np.array(time)\n",
    "    sparse_filter = (np.arange(x.shape[0]) % 5) == 0\n",
    "    ref_spin_density = np.roll(ref_sdw_avg,L//4,axis=1)\n",
    "    plt.plot(ref_Jt, ref_spin_density[:,i], \n",
    "             color=color_list[idx],linewidth=2)\n",
    "    plt.scatter( x[sparse_filter], spin_density[:,i][sparse_filter], \n",
    "#                 s = np.ones_like(sparse_filter)*169,\n",
    "                marker = marker[idx],\n",
    "                color=color_list[idx], label=r'$s_{'+str((i-8)%32+1)+'}$')\n",
    "    \n",
    "plt.xlabel(r'$Jt$',fontdict=font)\n",
    "plt.ylabel(r'$\\langle\\sigma_i(t)\\rangle$',fontdict=font)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(4,3)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(direction='in',labelsize=14)\n",
    "lgd = plt.legend(fontsize=16,bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plot_dir  = \"./output/{}/boundary_sdw_l{}T{}\".format( args.experiment_name, depth,T) + out_appdix\n",
    "plt.savefig(plot_dir,dpi=150,bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "####CGSP spectrum\n",
    "x = deepqd.root.net.target_bands.cpu().numpy()\n",
    "y = deepqd.root.net.norm.cpu().numpy()\n",
    "plt.bar(x[x<0],y[x<0]**2,width=0.02)\n",
    "plt.xticks([-0.24,-0.16,-0.08,0], [-0.24,-0.16,-0.08,0])\n",
    "plt.yticks(np.round(np.arange(5)*0.1,1),np.round(np.arange(5)*0.1,1))\n",
    "ax = plt.gca()\n",
    "ax.tick_params(direction='in',labelsize=14)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(3,2.5)\n",
    "plot_dir  = \"./output/{}/spectrum_l{}T{}\".format( args.experiment_name, depth,T) + out_appdix\n",
    "plt.savefig(plot_dir,dpi=150)\n",
    "plt.close()\n",
    "print(x)\n",
    "print('Emax={},Emin={},dE={}'.format(x.max(),x.min(),x[2]-x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params= 7163328\n",
      "0.011917420896063503\n"
     ]
    }
   ],
   "source": [
    "net = deepqd.root.net\n",
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('# params=',params)\n",
    "dimh =  deepqd.hilbert.dim_hilbert\n",
    "print(params/dimh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /home/bingjiay/gpfs/ControlQD/nn_data/s16n64-20b64-20MC4000hd128-cell4-lr0.001_skip*4/0.net\n",
      "sparsity tensor([59.1605, 60.1418, 60.9279, 61.4632, 61.5943, 61.0088, 59.0895, 54.7752,\n",
      "        47.6569, 44.6676, 50.0274, 57.2877, 62.5243, 64.9267, 64.5550, 59.9240,\n",
      "        60.3192, 72.8602, 76.4320, 74.5409, 67.0031, 70.4340, 75.8552, 76.8999,\n",
      "        72.0603, 70.8111, 80.4266, 72.9388, 85.3402, 80.6102, 85.0265, 72.5168,\n",
      "        83.3271, 75.2956, 66.7001, 74.5933, 80.9364, 79.1272, 79.1645, 75.8233,\n",
      "        67.1484, 75.4128, 69.7896, 68.6542, 64.5408, 73.3618, 64.6093, 58.2127,\n",
      "        70.1832, 68.5694, 69.5335, 54.4684, 54.4603, 52.0607, 63.4932, 57.9047,\n",
      "        50.8800, 52.3663, 52.1555, 48.3553, 38.3298, 38.1471, 38.1514, 49.1094],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "## observe middle layer output of amp-net\n",
    "\n",
    "\n",
    "deepqd = spectral_tree(args)\n",
    "deepqd.load_model('0',directory=directory)\n",
    "\n",
    "full_basis = deepqd.hilbert.get_full_basis()\n",
    "model = deepqd.root.net\n",
    "with th.no_grad():\n",
    "    psi_r, psi_i = model.faithful_forward(full_basis, deepqd.init_state) ## not normalized\n",
    "psi2 = (psi_r**2+psi_i**2)\n",
    "psi2normed = psi2 / psi2.sum(-1).unsqueeze(-1)\n",
    "sparsity = (psi2normed**0.5).sum(-1)\n",
    "print('sparsity',sparsity)\n",
    "\n",
    "\n",
    "# model = deepqd.root.net\n",
    "# s = th.tensor([-1,1]*20).unsqueeze(0)\n",
    "# s_nb,w_nb = deepqd.hilbert.get_neighbor_list_parallel(s)\n",
    "# psi_r, psi_i = model.forward(s_nb[0])\n",
    "\n",
    "\n",
    "# print(th.log(th.abs(psi_r))) \n",
    "\n",
    "# s,w=generate_ref_config(100, deepqd.init_state, gamma=0.1)\n",
    "# for i,q in enumerate(s):\n",
    "#     print(q)\n",
    "#     print(w[i])    \n",
    "\n",
    "\n",
    "##Loaded model from /home/bingjiay/gpfs/ControlQD/nn_data/s16n16-20b16-20MC4000hd128-cell4-lr0.001_skip*4/0.net\n",
    "# sparsity tensor([50.2663, 53.9543, 54.5530, 40.3695, 64.0339, 47.7522, 69.1760, 79.2141,\n",
    "#         68.7451, 75.2076, 69.7398, 63.2146, 62.1984, 57.4785, 50.0404, 35.8350],\n",
    "#        device='cuda:0', grad_fn=<SumBackward1>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3145, 16])\n",
      "torch.Size([3145])\n",
      "[6.7716001e-06 3.2554945e-04 6.4432726e-04 9.6310512e-04 1.2818830e-03\n",
      " 1.6006608e-03 1.9194387e-03 2.2382166e-03 2.5569943e-03 2.8757721e-03\n",
      " 3.1945501e-03 3.5133278e-03 3.8321058e-03 4.1508838e-03 4.4696615e-03\n",
      " 4.7884393e-03 5.1072170e-03 5.4259948e-03 5.7447730e-03 6.0635507e-03\n",
      " 6.3823285e-03]\n",
      "[3633  267   26   15   27    4    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0   28]\n",
      "norm tensor([0.0020, 0.0031, 0.0048, 0.0071, 0.0080, 0.0063, 0.0044, 0.0039, 0.0052,\n",
      "        0.0104, 0.0245, 0.0252, 0.0129, 0.0201, 0.0345, 0.0131, 0.0113, 0.0840,\n",
      "        0.0306, 0.0676, 0.1358, 0.0141, 0.1069, 0.1338, 0.0111, 0.1186, 0.1376,\n",
      "        0.1265, 0.1671, 0.0327, 0.1631, 0.1307, 0.1354, 0.2645, 0.0119, 0.1163,\n",
      "        0.2462, 0.0970, 0.0222, 0.1997, 0.2510, 0.0158, 0.0872, 0.2288, 0.0439,\n",
      "        0.2132, 0.0122, 0.0045, 0.2705, 0.1802], device='cuda:0',\n",
      "       grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from observer import *\n",
    "deepqd = spectral_tree(args)\n",
    "deepqd.load_model('0',directory=directory)\n",
    "model = deepqd.root.net\n",
    "s, w = generate_fid_config(4000, model, deepqd.init_state,gamma=0.5)\n",
    "unique_s = th.unique(s,dim=0)\n",
    "unique_w = th.unique(w,dim=0)\n",
    "print(th.unique(s,dim=0).shape)\n",
    "print(th.unique(w,dim=0).shape)\n",
    "\n",
    "\n",
    "hist, bin = np.histogram(w.cpu().numpy(), bins=20)\n",
    "print(bin)\n",
    "print(hist)\n",
    "\n",
    "\n",
    "ham = deepqd.hilbert\n",
    "ref_state = deepqd.init_state.reference_state\n",
    "nn_mask = th.abs(unique_s - ref_state).sum(-1) == 4\n",
    "nn_total_mask = th.abs(s - ref_state).sum(-1) == 4\n",
    "# print(nn_total_mask.sum())\n",
    "# print(unique_s[nn_mask])\n",
    "# print(unique_w[nn_mask])\n",
    "# print(unique_w.max())\n",
    "\n",
    "source_basis, weight_nbhood = ham.get_neighbor_list_parallel(ref_state.unsqueeze(0))\n",
    "source_basis = source_basis.reshape(-1,ham.nspin)\n",
    "sita_evaluated = HamNet(ham, model, source_basis, evaluate_source=True) ## all shapes=(ngroup, batchsize)\n",
    "ref_evaluated = HamNet(ham, deepqd.init_state, source_basis, evaluate_source=True) ## all shapes=(1, batchsize)\n",
    "Hpsi_r, Hpsi_i, psi_r, psi_i = faithful_transform(\n",
    "    sita_evaluated, ref_evaluated, model) ## all shapes=(ngroup, batchsize)\n",
    "\n",
    "# print('basis',source_basis-ref_state)\n",
    "# print('sita_r',sita_evaluated[2])\n",
    "# print('psi_r',psi_r)\n",
    "# print('Hpsi_r',Hpsi_r)\n",
    "amp=model._postprocess(model._preprocess(s,for_phase=False),model.amp_net(model._preprocess(s,for_phase=False)))\n",
    "\n",
    "bandwidth = (model.target_bands[-1]-model.target_bands[0])/(model.groups-1)\n",
    "scale_factor = (bandwidth/2)**2\n",
    "# weighted_variance, expH, varH, psipsi=sample_weighted_variance_unified_importance(4000, ham, deepqd.init_state, model)\n",
    "# print('weighted_variance',weighted_variance/scale_factor)\n",
    "# print('varH \\n ',np.round(th2np(varH/scale_factor),2) )\n",
    "# print('psipsi',psipsi)\n",
    "\n",
    "# weighted_variance, expH, exactvarH, psipsi=sample_weighted_variance_unified_importance_exact(ham, deepqd.init_state, model)\n",
    "# print('exact weighted_variance',weighted_variance/scale_factor)\n",
    "# print('exact varH \\n {}'.format(np.round(th2np((exactvarH-varH)/scale_factor),2)) )\n",
    "# print('psipsi',psipsi)\n",
    "# print('l1importance',model.subnet_l1importance())\n",
    "# psi_r, psi_i = model(ham.get_full_basis())\n",
    "# th.abs(psi_r).sum(-1)\n",
    "source_basis = ham.get_full_basis()\n",
    "# source_basis, weight_nbhood = ham.get_neighbor_list_parallel(ref_state.unsqueeze(0))\n",
    "# source_basis = source_basis.squeeze(0)\n",
    "sita_evaluated = HamNet(ham, model, source_basis, evaluate_source=True) ## all shapes=(ngroup, batchsize)\n",
    "ref_evaluated = HamNet(ham, deepqd.init_state, source_basis, evaluate_source=True) ## all shapes=(1, batchsize)\n",
    "Hpsi_r, Hpsi_i, psi_r, psi_i = faithful_transform(\n",
    "    sita_evaluated, ref_evaluated, model) ## all shapes=(ngroup, batchsize)\n",
    "# print(th.abs(psi_r).sum(0))\n",
    "norm = (psi_r**2).sum(-1)**0.5\n",
    "print('norm',norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "├── 0-1\n",
      "└── 0-2\n"
     ]
    }
   ],
   "source": [
    "from util import bit2integer\n",
    "deepqd = spectral_tree(args)\n",
    "deepqd.load_tree(directory)\n",
    "deepqd.load_all_model(directory=directory)\n",
    "\n",
    "net0 = deepqd.root.net\n",
    "net0.data_parallel()\n",
    "net01 = deepqd.root.children[0].net\n",
    "net01.data_parallel()\n",
    "\n",
    "net = net01\n",
    "\n",
    "\n",
    "hilbert = deepqd.hilbert\n",
    "full_basis= hilbert.get_full_basis()\n",
    "psi_r, psi_i = net(full_basis)\n",
    "\n",
    "active_amp_i = deepqd.reassign(th.zeros(deepqd.root.net.groups))\n",
    "active_amp_r = active_amp_i.clone()\n",
    "\n",
    "total_psi_r = (psi_r * net.groups_amplitude[:,None]).sum(0)\n",
    "total_psi_i = (psi_i * net.groups_amplitude[:,None]).sum(0)\n",
    "total_psi2 = total_psi_r**2 + total_psi_i**2\n",
    "# net_ref = deepqd.init_state\n",
    "\n",
    "net_ref = ensemble2ref_wrapper(net0, \n",
    "                               expH = net0.expH[1],\n",
    "                               amp_r = active_amp_r,\n",
    "                               amp_i = active_amp_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varH tensor([2.2620, 1.7883, 2.0908], device='cuda:0', dtype=torch.float64) expH tensor([0.0114, 0.0989, 0.1848], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0107, 1.0697, 0.9771], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0591, 0.9959, 0.9820], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0103, 0.9557, 1.1091], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0495, 1.0059, 1.1001], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0847, 0.9695, 1.0242], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0070, 1.0508, 0.0707], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.8776, 1.0806, 1.0326], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1670, 1.4129, 1.0098], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1743, 0.9378, 0.1941], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0148, 1.0224, 0.7199], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.6242, 1.0459, 0.8244], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0307, 0.8624, 1.0377], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 1.2294, -0.1819,  1.1576], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.4783, 1.0841, 1.0778], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9665, 1.2588, 0.9323], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.7088, 1.0015, 1.0028], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.5660, 0.8954, 0.9057], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.5053, 1.0646, 0.9714], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9050, 1.9507, 0.9447], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 0.3376,  0.9173, -0.5056], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.7837, 0.1722, 1.0441], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.8941, 0.8586, 1.0144], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9411, 1.0854, 1.0377], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9099, 1.0296, 0.9109], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0363, 1.0339, 0.2348], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0664, 0.8507, 1.0083], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.2970, 1.2163, 0.9865], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0179, 0.9197, 1.0149], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1654, 0.8976, 0.9598], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.8871, 1.0026, 0.7477], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.8939, 1.0641, 0.9654], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.8217, 1.1313, 1.1096], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1058, 0.9431, 0.8826], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.0568, 0.9569, 1.5515], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0694, 0.8069, 1.2132], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.5988, 0.9368, 1.0002], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9637, 1.2718, 0.8700], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0436, 1.1678, 0.8410], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1662, 1.0099, 2.2417], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.3769, 0.8885, 1.0523], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9974, 1.0600, 0.9311], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1447, 1.0813, 0.8576], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0820, 4.5960, 0.7120], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.2985, 1.0262, 0.6810], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([-0.2382,  0.9268,  0.9417], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1081, 0.0063, 0.4293], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9943, 1.0557, 0.9444], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.2705, 0.9868, 0.9585], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9980, 1.4368, 0.7357], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.6109, 0.9303, 1.1304], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9205, 0.5877, 0.9913], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 1.0584, -7.5587,  1.0027], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9412, 1.1305, 1.1274], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.7599, 1.0912, 0.8201], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0437, 0.9762, 0.9636], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9980, 1.2993, 0.7726], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 0.6425, -0.0160,  1.4043], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1373, 0.9479, 0.9137], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9638, 0.9273, 0.8109], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9981, 1.0188, 0.9227], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 0.9235, -0.1622,  0.9958], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0810, 1.0825, 0.9652], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([-0.9387,  0.9488,  1.0124], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1566, 0.9718, 0.9004], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0016, 1.0442, 0.6990], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0130, 1.0532, 0.8807], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.4908, 0.9383, 0.9715], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 0.1842,  0.8633, -0.5175], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.7507, 0.8651, 0.9087], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1384, 1.0635, 0.8807], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0160, 1.0495, 0.9098], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.2242, 1.2041, 1.3599], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.7339, 1.0533, 1.1500], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0563, 0.9269, 1.0749], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 1.1481,  1.0014, -0.0555], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.2692, 0.6713, 0.9158], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.2635, 0.9914, 1.0490], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0790, 1.6264, 0.5252], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.3776, 0.8202, 1.0384], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.0572, 0.9004, 0.9316], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.7551, 0.9383, 0.9354], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0648, 1.0918, 0.9419], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9646, 1.0197, 0.9641], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0395, 1.0422, 1.0952], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.8959, 1.0162, 0.9620], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.7162, 0.8829, 2.0933], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0310, 0.7415, 2.8649], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0126, 0.9668, 0.7774], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.1464, 0.9314, 1.0434], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9722, 1.2939, 0.9211], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 1.0002, -0.7768,  0.8198], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0717, 1.0448, 1.4563], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9277, 0.9804, 1.4197], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.5551, 1.0698, 1.2885], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0895, 1.0062, 0.7625], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.8947, 0.9467, 1.1103], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9884, 0.9839, 0.8556], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([0.9949, 0.9499, 1.0448], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([1.0024, 0.9341, 1.0284], device='cuda:0', dtype=torch.float64)\n",
      "incorrect/correct tensor([ 1.0548,  0.7746, 29.2812], device='cuda:0', dtype=torch.float64)\n",
      "var_simple tensor([2.2218, 1.8399, 2.2007], device='cuda:0', dtype=torch.float64) \n",
      " varH tensor([2.2260, 1.8440, 2.2169], device='cuda:0', dtype=torch.float64) \n",
      " expH tensor([0.0113, 0.0989, 0.1849], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "with th.no_grad():\n",
    "    exp_dict = deepqd.exact_all_expectation(net, net_ref)\n",
    "    bw = (net.target_bands[1]-net.target_bands[0])\n",
    "print(\n",
    "    'varH',exp_dict['variance'] / (bw/2)**2,\n",
    "    'expH', exp_dict['expH']\n",
    ")\n",
    "\n",
    "expHl=[]\n",
    "varHl=[]\n",
    "varHl_simple = []\n",
    "for i in range(100):\n",
    "    with th.no_grad():\n",
    "        batchsize = 500\n",
    "        tol=0.02\n",
    "        target_bands = net.target_bands[:,None]\n",
    "        dim_group, dim_batch = 0, 1\n",
    "        target_bands = net.target_bands[:,None]\n",
    "        basis_input_var, mcWeight_var = net.generate(batchsize,tol=tol)\n",
    "        sita_r, sita_i = net(basis_input_var)\n",
    "        # sita_r, sita_i = self.cheapnet(net, basis_input_var)\n",
    "        Hsita_r, Hsita_i = deepqd.Hnet(net, basis_input_var)\n",
    "        ## compute quantum expectaions\n",
    "        HmEsita_norm2 = (Hsita_r - sita_r * target_bands)**2 + (Hsita_i - sita_i * target_bands)**2\n",
    "        sita_norm2 = sita_r**2 + sita_i**2\n",
    "        varH = (HmEsita_norm2 / mcWeight_var).mean(dim_batch) \n",
    "        varH_reg = (HmEsita_norm2 / mcWeight_var).mean(dim_batch) / (sita_norm2/mcWeight_var).mean(dim_batch)\n",
    "        ratio = (\n",
    "            varH - exp_dict['variance']\n",
    "                )/(\n",
    "            varH_reg - exp_dict['variance']\n",
    "        )\n",
    "        print(\"incorrect/correct {}\".format(ratio))\n",
    "        expH = ( (sita_r * Hsita_r + sita_i * Hsita_i) \n",
    "                    / mcWeight_var ).mean(dim_batch) / (sita_norm2/mcWeight_var).mean(dim_batch)\n",
    "        expHl.append(expH)\n",
    "        varHl.append(varH_reg)\n",
    "        varHl_simple.append(varH)\n",
    "print('var_simple', sum(varHl_simple)/100 / (bw/2)**2,'\\n',\n",
    "    'varH',sum(varHl)/100 / (bw/2)**2,'\\n',\n",
    "     'expH', sum(expHl)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
